"""
Extract ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸.

ìˆœì°¨ ì¶”ì¶œê³¼ ë³‘ë ¬ ì¶”ì¶œì˜ ì„±ëŠ¥ì„ ë¹„êµ ì¸¡ì •í•©ë‹ˆë‹¤.
S3 ì ì¬ ì—†ì´ ìˆœìˆ˜ API ì¶”ì¶œ ì‹œê°„ë§Œ ì¸¡ì •í•©ë‹ˆë‹¤.

ì‚¬ìš©ë²•:
    # ì „ì²´ ì—”í‹°í‹° ì¸¡ì • (ìˆœì°¨ + ë³‘ë ¬ ë¹„êµ)
    uv run python scripts/benchmark_extract.py

    # íŠ¹ì • ì—”í‹°í‹°ë§Œ ì¸¡ì •
    uv run python scripts/benchmark_extract.py --entity platforms

    # ìˆœì°¨ë§Œ ì¸¡ì •
    uv run python scripts/benchmark_extract.py --mode sequential

    # ë³‘ë ¬ë§Œ ì¸¡ì •
    uv run python scripts/benchmark_extract.py --mode concurrent

    # ë°˜ë³µ íšŸìˆ˜ ì§€ì •
    uv run python scripts/benchmark_extract.py --entity platforms --runs 3

    # ë³‘ë ¬ ë°°ì¹˜ í¬ê¸° ì§€ì •
    uv run python scripts/benchmark_extract.py --batch-size 8
"""

import argparse
import asyncio
import json
import sys
from dataclasses import asdict, dataclass
from datetime import datetime
from pathlib import Path
from time import perf_counter

import httpx
from loguru import logger

from src.config import settings
from src.pipeline.auth import StaticAuthProvider
from src.pipeline.rate_limiter import IgdbRateLimiter
from src.pipeline.registry import ALL_ENTITIES


@dataclass
class BenchmarkResult:
    """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤."""

    entity_name: str
    mode: str  # "sequential" or "concurrent"
    record_count: int
    elapsed_seconds: float
    records_per_second: float
    api_calls: int
    batch_size: int | None  # concurrent ëª¨ë“œì—ì„œë§Œ ì‚¬ìš©
    timestamp: str


@dataclass
class ComparisonResult:
    """ìˆœì°¨/ë³‘ë ¬ ë¹„êµ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤."""

    entity_name: str
    sequential_elapsed: float
    concurrent_elapsed: float
    speedup: float
    record_count: int


async def benchmark_entity_sequential(
    entity_name: str,
    extractor_cls: type,
    http_client: httpx.AsyncClient,
    auth_provider: StaticAuthProvider,
    client_id: str,
) -> BenchmarkResult:
    """
    ë‹¨ì¼ ì—”í‹°í‹°ì˜ ìˆœì°¨ ì¶”ì¶œ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

    Args:
        entity_name: ì—”í‹°í‹° ì´ë¦„
        extractor_cls: Extractor í´ë˜ìŠ¤
        http_client: HTTP í´ë¼ì´ì–¸íŠ¸
        auth_provider: ì¸ì¦ ì œê³µì
        client_id: IGDB í´ë¼ì´ì–¸íŠ¸ ID

    Returns:
        BenchmarkResult: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
    """
    extractor = extractor_cls(
        client=http_client,
        auth_provider=auth_provider,
        client_id=client_id,
    )

    logger.info(f"[{entity_name}] ìˆœì°¨ ì¶”ì¶œ ì‹œì‘...")
    start_time = perf_counter()

    record_count = 0
    api_calls = 0

    async for _ in extractor.extract():
        record_count += 1
        if record_count % extractor.limit == 1:
            api_calls += 1

    elapsed = perf_counter() - start_time
    records_per_second = record_count / elapsed if elapsed > 0 else 0

    result = BenchmarkResult(
        entity_name=entity_name,
        mode="sequential",
        record_count=record_count,
        elapsed_seconds=round(elapsed, 2),
        records_per_second=round(records_per_second, 2),
        api_calls=api_calls,
        batch_size=None,
        timestamp=datetime.now().isoformat(),
    )

    logger.success(
        f"[{entity_name}] ìˆœì°¨ ì™„ë£Œ: {record_count:,}ê°œ / {elapsed:.2f}ì´ˆ "
        f"({records_per_second:.2f} rec/sec, {api_calls} API calls)"
    )

    return result


async def benchmark_entity_concurrent(
    entity_name: str,
    extractor_cls: type,
    http_client: httpx.AsyncClient,
    auth_provider: StaticAuthProvider,
    client_id: str,
    rate_limiter: IgdbRateLimiter,
    batch_size: int = 4,
) -> BenchmarkResult:
    """
    ë‹¨ì¼ ì—”í‹°í‹°ì˜ ë³‘ë ¬ ì¶”ì¶œ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.

    Args:
        entity_name: ì—”í‹°í‹° ì´ë¦„
        extractor_cls: Extractor í´ë˜ìŠ¤
        http_client: HTTP í´ë¼ì´ì–¸íŠ¸
        auth_provider: ì¸ì¦ ì œê³µì
        client_id: IGDB í´ë¼ì´ì–¸íŠ¸ ID
        rate_limiter: API í˜¸ì¶œ ì†ë„ ì œí•œê¸°
        batch_size: ë™ì‹œ ìš”ì²­ í˜ì´ì§€ ìˆ˜

    Returns:
        BenchmarkResult: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
    """
    extractor = extractor_cls(
        client=http_client,
        auth_provider=auth_provider,
        client_id=client_id,
        rate_limiter=rate_limiter,
    )

    logger.info(f"[{entity_name}] ë³‘ë ¬ ì¶”ì¶œ ì‹œì‘ (batch_size={batch_size})...")
    start_time = perf_counter()

    record_count = 0
    api_calls = 0

    async for _ in extractor.extract_concurrent(batch_size=batch_size):
        record_count += 1
        if record_count % extractor.limit == 1:
            api_calls += 1

    elapsed = perf_counter() - start_time
    records_per_second = record_count / elapsed if elapsed > 0 else 0

    result = BenchmarkResult(
        entity_name=entity_name,
        mode="concurrent",
        record_count=record_count,
        elapsed_seconds=round(elapsed, 2),
        records_per_second=round(records_per_second, 2),
        api_calls=api_calls,
        batch_size=batch_size,
        timestamp=datetime.now().isoformat(),
    )

    logger.success(
        f"[{entity_name}] ë³‘ë ¬ ì™„ë£Œ: {record_count:,}ê°œ / {elapsed:.2f}ì´ˆ "
        f"({records_per_second:.2f} rec/sec, {api_calls} API calls)"
    )

    return result


async def run_benchmark(
    entities: list[str] | None = None,
    mode: str = "both",
    runs: int = 1,
    batch_size: int = 4,
) -> tuple[list[BenchmarkResult], list[ComparisonResult]]:
    """
    ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

    Args:
        entities: ì¸¡ì •í•  ì—”í‹°í‹° ëª©ë¡ (Noneì´ë©´ ì „ì²´)
        mode: "sequential", "concurrent", "both"
        runs: ë°˜ë³µ íšŸìˆ˜
        batch_size: ë³‘ë ¬ ì¶”ì¶œ ì‹œ ë™ì‹œ ìš”ì²­ í˜ì´ì§€ ìˆ˜

    Returns:
        tuple: (ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ëª©ë¡, ë¹„êµ ê²°ê³¼ ëª©ë¡)
    """
    client_id = settings.igdb_client_id
    static_token = settings.igdb_static_token

    if not client_id or not static_token:
        logger.error("IGDB_CLIENT_ID ë˜ëŠ” IGDB_STATIC_TOKENì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        sys.exit(1)

    auth_provider = StaticAuthProvider(token=static_token)
    rate_limiter = IgdbRateLimiter(max_concurrency=4, requests_per_second=4)

    target_entities = entities or list(ALL_ENTITIES.keys())
    all_results: list[BenchmarkResult] = []
    comparisons: list[ComparisonResult] = []

    async with httpx.AsyncClient(timeout=120.0) as http_client:
        for run_num in range(1, runs + 1):
            if runs > 1:
                logger.info(f"=== Run {run_num}/{runs} ===")

            for entity_name in target_entities:
                if entity_name not in ALL_ENTITIES:
                    logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” ì—”í‹°í‹°: {entity_name}")
                    continue

                extractor_cls = ALL_ENTITIES[entity_name]
                seq_result = None
                con_result = None

                # ìˆœì°¨ ì¶”ì¶œ
                if mode in ("sequential", "both"):
                    seq_result = await benchmark_entity_sequential(
                        entity_name=entity_name,
                        extractor_cls=extractor_cls,
                        http_client=http_client,
                        auth_provider=auth_provider,
                        client_id=client_id,
                    )
                    all_results.append(seq_result)

                # ë³‘ë ¬ ì¶”ì¶œ
                if mode in ("concurrent", "both"):
                    con_result = await benchmark_entity_concurrent(
                        entity_name=entity_name,
                        extractor_cls=extractor_cls,
                        http_client=http_client,
                        auth_provider=auth_provider,
                        client_id=client_id,
                        rate_limiter=rate_limiter,
                        batch_size=batch_size,
                    )
                    all_results.append(con_result)

                # ë¹„êµ ê²°ê³¼ ìƒì„±
                if seq_result and con_result:
                    speedup = (
                        seq_result.elapsed_seconds / con_result.elapsed_seconds
                        if con_result.elapsed_seconds > 0
                        else 0
                    )
                    comparisons.append(
                        ComparisonResult(
                            entity_name=entity_name,
                            sequential_elapsed=seq_result.elapsed_seconds,
                            concurrent_elapsed=con_result.elapsed_seconds,
                            speedup=round(speedup, 2),
                            record_count=seq_result.record_count,
                        )
                    )

    return all_results, comparisons


def save_results(
    results: list[BenchmarkResult],
    comparisons: list[ComparisonResult],
    output_path: Path,
    mode: str,
    batch_size: int,
) -> None:
    """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # ëª¨ë“œë³„ ê²°ê³¼ ë¶„ë¦¬
    seq_results = [r for r in results if r.mode == "sequential"]
    con_results = [r for r in results if r.mode == "concurrent"]

    data = {
        "benchmark_type": f"extract_{mode}",
        "timestamp": datetime.now().isoformat(),
        "environment": {
            "python_version": sys.version,
            "platform": sys.platform,
        },
        "config": {
            "mode": mode,
            "batch_size": batch_size,
            "rate_limit": {
                "max_concurrency": 4,
                "requests_per_second": 4,
            },
        },
        "results": {
            "sequential": [asdict(r) for r in seq_results] if seq_results else None,
            "concurrent": [asdict(r) for r in con_results] if con_results else None,
        },
        "comparisons": [asdict(c) for c in comparisons] if comparisons else None,
        "summary": {
            "sequential": {
                "total_records": sum(r.record_count for r in seq_results),
                "total_elapsed_seconds": round(
                    sum(r.elapsed_seconds for r in seq_results), 2
                ),
                "total_api_calls": sum(r.api_calls for r in seq_results),
            }
            if seq_results
            else None,
            "concurrent": {
                "total_records": sum(r.record_count for r in con_results),
                "total_elapsed_seconds": round(
                    sum(r.elapsed_seconds for r in con_results), 2
                ),
                "total_api_calls": sum(r.api_calls for r in con_results),
            }
            if con_results
            else None,
            "average_speedup": (
                round(sum(c.speedup for c in comparisons) / len(comparisons), 2)
                if comparisons
                else None
            ),
        },
    }

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    logger.info(f"ê²°ê³¼ ì €ì¥: {output_path}")


def print_summary(
    results: list[BenchmarkResult], comparisons: list[ComparisonResult], mode: str
) -> None:
    """ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    seq_results = [r for r in results if r.mode == "sequential"]
    con_results = [r for r in results if r.mode == "concurrent"]

    print("\n" + "=" * 80)
    if mode == "both":
        print("ğŸ“Š Extract ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ (ìˆœì°¨ vs ë³‘ë ¬ ë¹„êµ)")
    elif mode == "sequential":
        print("ğŸ“Š Extract ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ (ìˆœì°¨ ì²˜ë¦¬)")
    else:
        print("ğŸ“Š Extract ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ (ë³‘ë ¬ ì²˜ë¦¬)")
    print("=" * 80)

    if comparisons:
        # ë¹„êµ ëª¨ë“œ
        print(
            f"{'ì—”í‹°í‹°':<25} {'ë ˆì½”ë“œ':>10} {'ìˆœì°¨(ì´ˆ)':>10} {'ë³‘ë ¬(ì´ˆ)':>10} {'Speedup':>10}"
        )
        print("-" * 80)

        for c in comparisons:
            print(
                f"{c.entity_name:<25} {c.record_count:>10,} "
                f"{c.sequential_elapsed:>10.2f} {c.concurrent_elapsed:>10.2f} "
                f"{c.speedup:>9.2f}x"
            )

        print("-" * 80)

        total_records = sum(c.record_count for c in comparisons)
        total_seq = sum(c.sequential_elapsed for c in comparisons)
        total_con = sum(c.concurrent_elapsed for c in comparisons)
        total_speedup = total_seq / total_con if total_con > 0 else 0

        print(
            f"{'ì´ê³„':<25} {total_records:>10,} "
            f"{total_seq:>10.2f} {total_con:>10.2f} "
            f"{total_speedup:>9.2f}x"
        )

    else:
        # ë‹¨ì¼ ëª¨ë“œ
        target_results = seq_results or con_results
        print(f"{'ì—”í‹°í‹°':<25} {'ë ˆì½”ë“œ':>10} {'ì‹œê°„(ì´ˆ)':>10} {'rec/sec':>10}")
        print("-" * 80)

        for r in target_results:
            print(
                f"{r.entity_name:<25} {r.record_count:>10,} "
                f"{r.elapsed_seconds:>10.2f} {r.records_per_second:>10.2f}"
            )

        print("-" * 80)
        total_records = sum(r.record_count for r in target_results)
        total_time = sum(r.elapsed_seconds for r in target_results)
        avg_rps = total_records / total_time if total_time > 0 else 0

        print(f"{'ì´ê³„':<25} {total_records:>10,} {total_time:>10.2f} {avg_rps:>10.2f}")

    print("=" * 80)


def main() -> None:
    """ë©”ì¸ í•¨ìˆ˜."""
    parser = argparse.ArgumentParser(description="Extract ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    parser.add_argument(
        "--entity",
        type=str,
        help="ì¸¡ì •í•  ì—”í‹°í‹° ì´ë¦„ (ì˜ˆ: games, platforms). ë¯¸ì§€ì •ì‹œ ì „ì²´ ì¸¡ì •",
    )
    parser.add_argument(
        "--mode",
        type=str,
        choices=["sequential", "concurrent", "both"],
        default="both",
        help="ì¸¡ì • ëª¨ë“œ: sequential(ìˆœì°¨), concurrent(ë³‘ë ¬), both(ë¹„êµ) (ê¸°ë³¸: both)",
    )
    parser.add_argument(
        "--batch-size",
        type=int,
        default=4,
        help="ë³‘ë ¬ ì¶”ì¶œ ì‹œ ë™ì‹œ ìš”ì²­ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸: 4)",
    )
    parser.add_argument(
        "--runs",
        type=int,
        default=1,
        help="ë°˜ë³µ íšŸìˆ˜ (ê¸°ë³¸: 1)",
    )
    parser.add_argument(
        "--output",
        type=str,
        default=None,
        help="ê²°ê³¼ ì €ì¥ ê²½ë¡œ (ì˜ˆ: docs/refactoring/benchmarks/data/result.json)",
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="ìƒì„¸ ë¡œê·¸ ìˆ¨ê¸°ê¸°",
    )
    args = parser.parse_args()

    # ë¡œê¹… ì„¤ì •
    logger.remove()
    if not args.quiet:
        logger.add(sys.stderr, level="INFO")
    else:
        logger.add(sys.stderr, level="WARNING")

    # ì—”í‹°í‹° ëª©ë¡
    entities = [args.entity] if args.entity else None

    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    logger.info(f"=== Extract ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ (mode={args.mode}) ===")
    results, comparisons = asyncio.run(
        run_benchmark(
            entities=entities,
            mode=args.mode,
            runs=args.runs,
            batch_size=args.batch_size,
        )
    )

    # ê²°ê³¼ ì¶œë ¥
    print_summary(results, comparisons, args.mode)

    # ê²°ê³¼ ì €ì¥
    if args.output:
        output_path = Path(args.output)
    else:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = Path(
            f"docs/refactoring/benchmarks/data/extract_{args.mode}_{timestamp}.json"
        )

    save_results(results, comparisons, output_path, args.mode, args.batch_size)


if __name__ == "__main__":
    main()
